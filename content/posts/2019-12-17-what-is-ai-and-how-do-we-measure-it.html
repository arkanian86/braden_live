---
title: What is AI and how do we measure it?
description: Francois Chollet's latest paper, "The Measure of Intelligence," provides a great understanding of how to define intelligence - and potentially how to measure it.
author: Braden
date: '2019-12-19'
slug: what-is-ai
categories:
  - Paper reviews
tags:
  - AI
  - data science
draft: yes
twitter:
  card: summaryasdf
  site: '@braden_live'
  title: Special Title for the Cardasdfasdf
  description: Special Description for the card max. 200 charactersasdfasdfadsf
  image: 'https://www.bradenlive.com/posts/2019-12-17-enron-broadband_files/Enron-E.png'
---



<p>This summer, I interned at an AI startup called <a href="www.narrativescience.com">Narrative Science</a>, working on a product called <a href="www.narrativescience.com/lexio">Lexio</a> as a product manager. Lexio connects to a customer’s Salesforce data and uses natural language generation (NLG) to write stories about the data - for example, replacing the status update a sales rep might send their boss at the end of every week. I knew the product was AI because it replaced work that a human was doing.</p>
<p>In the fall, while taking classes at Kellogg, I interned at <a href="www.tensilityvc.com">Tensility Venture Partners</a>, a seed-stage VC firm focused on enterprise applications of AI. I had the opportunity to sit through more than 50 founders pitching their AI startups. We viewed products as truly AI if the product was not only predictive, but prescriptive - giving actionable information to achieve a specific outcome.</p>
<p>Throughout these internships and in my classes at Kellogg, I’ve never found a good definition of AI. Machine learning models can be prescriptive; for example, <a href="https://www.researchgate.net/publication/227704541_Next-product-to-buy_models_for_cross-selling_applications">next product to buy algorithms</a> can tell a marketer when and which marketing email to send to customers in order to maximize purchases. But machine learning is just statistics - it’s not intelligent as humans would recognize it.</p>
<p><a href="https://xkcd.com/1838/"><img src="/posts/2019-12-17-what-is-ai-and-how-do-we-measure-it_files/machine_learning_2x.png" alt="https://xkcd.com/1838" style="width:40.0%" /></a></p>
<p>The <a href="https://www.google.com/search?q=define%3A+artificial+intelligence&amp;oq=define%3A+artificial+intelligence&amp;aqs=chrome..69i57j69i58.4225j0j7&amp;sourceid=chrome&amp;ie=UTF-8">Oxford Dictionary</a> defines AI as</p>
<blockquote>
<p>the theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.</p>
</blockquote>
<p>but this leaves me wanting more as well. Recent heralded advances in supposed AI like <a href="https://en.wikipedia.org/wiki/AlphaGo">AlphaGo</a> and <a href="https://openai.com/projects/five/">OpenAI Five</a> play games that humans normally play, beating the best humans in the world. But can these intelligent machines drive a car? or even navigate a maze?</p>
<hr />
<p>Reading Francois Chollet’s latest paper, <em>The Measure of Intelligence</em> gave me a much better understanding of how to evaluate AI. Chollet proposes an actionable definition for AI as well as a way to measure it. His goal is</p>
<blockquote>
<p>to point out the implicit assumptions our field has been working from, correct some of its most salient biases, and provide an actionable formal definition and measurement benchmark for human-like general intelligence, leveraging modern insight from developmental cognitive psychology.</p>
</blockquote>
<p>The paper is organized into three sections: first, Chollet provides context and history around intelligence and AI, how both have been classically defined, and how this has impacted research into AI. Second, he proposes a new definition for AI. Finally, he provides a new dataset that can be used to benchmark AI against a formal definition of AI. I found all three sections to be extraordinarily useful in understanding AI and how to best think about it. What follows is my main takeaways from the paper.</p>
<div id="context-and-history" class="section level3">
<h3>Context and history</h3>
<p>Traditionally, the fields of cognitive science and psychology has struggled to define intelligence. There have been two diverging visions for defining intelligence:</p>
<ol style="list-style-type: decimal">
<li>The mind is a “<strong>relatively static assembly of special purpose mechanisms</strong> developed by evolution, only capable of learning what it is programmed to acquire”</li>
<li>The mind is a “<strong>general purpose ‘blank slate’</strong> capable of turning abitrary experience into knowledge and skills, and that could be directed at any problem.”</li>
</ol>
<p>In terms of human evolution, I tend to lean towards the latter view. How could a mind evolve into a collection of special purpose mechanisms? How did it know ahead of time what mechanisms to prioritize unless it first started as a blank slate?</p>
<p>At a very high level, it appears that much of the so-called progress in AI recently has been in favor of the former. AI algorithms are specially built to accomplish very specific tasks, but struggle when presented with a new task even if that new task is very similar–for example, some computer vision applications have trouble recognizing images that have been <a href="https://www.brown.edu/news/2018-07-30/same-different">turned sideways</a>. Other well-known examples of AI that out-perform humans in certain tasks but exhibit no recognizable intelligence include applications in games like <a href="https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)">Chess (Deep Blue)</a>, <a href="https://en.wikipedia.org/wiki/AlphaGo">Go (AlphaGo)</a>, or <a href="https://en.wikipedia.org/wiki/OpenAI_Five">DotA2 (OpenAI Five).</a></p>
<p>Conversely, the rise of machine learning models, where AI “learns” its skills via the training data, can be viewed through the blank-slate lens.</p>
<p>Regardless, this dichotomy brings into focus some of the central issues at play in defining AI, and in pushing forward AI research. The interplay between “crystallized skills” (i.e., mechanisms developed by evolution in humans or in some manner hard-coded into AI algorithms) and ability to learn new skills are key in understanding and defining AI, and has been the fundamental difficulty in AI since its inception.</p>
<p>Finally, these competing visions also present difficulties when it comes to evaluating intelligence. We can either:</p>
<ol style="list-style-type: decimal">
<li>measure skills (the static assembly of special-purpose mechanisms vision)</li>
<li>measure broad abilities (the blank-slate vision)</li>
</ol>
<p>Chollet describes the various methods that are currently used to evaulate AI, which include human review, white-box analysis, peer confrontation, and benchmarks. Flaws exist in each method; furthermore, models are not comparable to each other without an accepted overarching definition of intelligence.</p>
</div>
<div id="a-new-definition-for-ai" class="section level3">
<h3>A new definition for AI</h3>
<p>The difficulties of definining intelligence, and thus proving progress towards it, are perfectly captured by Scott Alexander at <a href="https://slatestarcodex.com/2019/02/28/meaningful/">Slate Star Codex</a>. Two children debate the intelligence of an AI algorithm…then two chemists debate the intelligence of the children, then two angels debate the intelligence of the human chemists. Finally, God chimes in regarding the author of the story:</p>
<blockquote>
<p>God sits in the highest heaven, alone.</p>
<p>“Wow!” He thinks to Himself, “that cellular automaton sure is producing some pretty patterns today. I wonder what it will do next!”</p>
</blockquote>
</div>
