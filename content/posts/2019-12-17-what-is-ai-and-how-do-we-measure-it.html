---
title: What is AI and how do we measure it?
description: Francois Chollet's latest paper, "The Measure of Intelligence," provides a great understanding of how to define intelligence - and potentially how to measure it.
author: Braden
date: '2019-12-19'
slug: what-is-ai
categories:
  - Paper reviews
tags:
  - AI
  - data science
draft: yes
twitter:
  card: summaryasdf
  site: '@braden_live'
  title: Special Title for the Cardasdfasdf
  description: Special Description for the card max. 200 charactersasdfasdfadsf
  image: 'https://www.bradenlive.com/posts/2019-12-17-enron-broadband_files/Enron-E.png'
---



<p>This summer, I interned at an AI startup called <a href="www.narrativescience.com">Narrative Science</a>, working on a product called <a href="www.narrativescience.com/lexio">Lexio</a> as a product manager. Lexio connects to a customer’s Salesforce data and uses natural language generation (NLG) to write stories about the data - for example, replacing the status update a sales rep might send their boss at the end of every week. I knew the product was AI because it replaced work that a human was doing.</p>
<p>In the fall, while taking classes at Kellogg, I interned at <a href="www.tensilityvc.com">Tensility Venture Partners</a>, a seed-stage VC firm focused on enterprise applications of AI. I had the opportunity to sit through more than 50 founders pitching their AI startups. We viewed products as truly AI if the product was not only predictive, but prescriptive - giving actionable information to achieve a specific outcome.</p>
<p>Throughout these internships and in my classes at Kellogg, I’ve never found a good definition of AI. Machine learning models can be prescriptive; for example, <a href="https://www.researchgate.net/publication/227704541_Next-product-to-buy_models_for_cross-selling_applications">next product to buy algorithms</a> can tell a marketer when and which marketing email to send to customers in order to maximize purchases. But machine learning is just statistics - it’s not intelligent as humans would recognize it.</p>
<p><a href="https://xkcd.com/1838/"><img src="/posts/2019-12-17-what-is-ai-and-how-do-we-measure-it_files/machine_learning_2x.png" alt="https://xkcd.com/1838" style="width:40.0%" /></a></p>
<p>The <a href="https://www.google.com/search?q=define%3A+artificial+intelligence&amp;oq=define%3A+artificial+intelligence&amp;aqs=chrome..69i57j69i58.4225j0j7&amp;sourceid=chrome&amp;ie=UTF-8">Oxford Dictionary</a> defines AI as <strong>(change this to a more reputable AI source)</strong></p>
<blockquote>
<p>the theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.</p>
</blockquote>
<p>but this leaves me wanting more as well. Recent heralded advances in supposed AI like <a href="https://en.wikipedia.org/wiki/AlphaGo">AlphaGo</a> and <a href="https://openai.com/projects/five/">OpenAI Five</a> play games that humans normally play, beating the best humans in the world. But can these intelligent machines drive a car? or even navigate a maze?</p>
<hr />
<p>Reading Francois Chollet’s latest paper, <em>The Measure of Intelligence</em> gave me a much better understanding of how to evaluate AI. Chollet proposes an actionable definition for AI as well as a way to measure it. His goal is</p>
<blockquote>
<p>to point out the implicit assumptions our field has been working from, correct some of its most salient biases, and provide an actionable formal definition and measurement benchmark for human-like general intelligence, leveraging modern insight from developmental cognitive psychology.</p>
</blockquote>
<p>The paper is organized into three sections: first, Chollet provides context and history around intelligence and AI, how both have been classically defined, and how this has impacted research into AI. Second, he proposes a new definition for AI. Finally, he provides a new dataset that can be used to benchmark AI against a formal definition of AI. I found all three sections to be extraordinarily useful in understanding AI and how to best think about it. What follows is my main takeaways from the paper.</p>
<div id="context-and-history" class="section level3">
<h3>Context and history</h3>
<p>Traditionally, the fields of cognitive science and psychology has struggled to define intelligence. There have been two diverging visions for defining intelligence:</p>
<ol style="list-style-type: decimal">
<li>The mind is a “relatively static assembly of special purpose mechanisms developed by evolution, only capable of learning what it is programmed to acquire”</li>
<li>The mind is a “general purpose ‘blank slate’ capable of turning abitrary experience into knowledge and skills, and that could be directed at any problem.”</li>
</ol>
<p>In terms of human evolution, I tend to lean towards the latter view. How could a mind evolve into a collection of special purpose mechanisms? How did it know ahead of time what mechanisms to prioritize unless it first started as a blank slate?</p>
<p>Regardless, this dichotomy brings into focus some of the central issues at play in defining AI, and in pushing forward AI research. The interplay between “crystallized skills” (i.e., mechanisms developed by evolution in humans or in some manner hard-coded into AI algorithms) and ability to learn new skills are key in understanding and defining AI.</p>
</div>
