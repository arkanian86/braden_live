---
title: What is AI and how do we measure it?
description: Francois Chollet's latest paper, "The Measure of Intelligence," provides a great understanding of how to define intelligence - and potentially how to measure it.
author: Braden
date: '2019-12-19'
slug: what-is-ai
categories:
  - Paper reviews
tags:
  - AI
  - data science
draft: yes
twitter:
  card: summaryasdf
  site: '@braden_live'
  title: Special Title for the Cardasdfasdf
  description: Special Description for the card max. 200 charactersasdfasdfadsf
  image: 'https://www.bradenlive.com/posts/2019-12-17-enron-broadband_files/Enron-E.png'
---

This summer, I interned at an AI startup called [Narrative Science](www.narrativescience.com), working on a product called [Lexio](www.narrativescience.com/lexio) as a product manager. Lexio connects to a customer's Salesforce data and uses natural language generation (NLG) to write stories about the data - for example, replacing the status update a sales rep might send their boss at the end of every week. I knew the product was AI because it replaced work that a human was doing.

In the fall, while taking classes at Kellogg, I interned at [Tensility Venture Partners](www.tensilityvc.com), a seed-stage VC firm focused on enterprise applications of AI. I had the opportunity to sit through more than 50 founders pitching their AI startups. We viewed products as truly AI if the product was not only predictive, but prescriptive - giving actionable information to achieve a specific outcome.

Throughout these internships and in my classes at Kellogg, I've never found a good definition of AI. Machine learning models can be prescriptive; for example, [next product to buy algorithms](https://www.researchgate.net/publication/227704541_Next-product-to-buy_models_for_cross-selling_applications) can tell a marketer when and which marketing email to send to customers in order to maximize purchases. But machine learning is just statistics - it's not intelligent as humans would recognize it.

[![https://xkcd.com/1838](/posts/2019-12-17-what-is-ai-and-how-do-we-measure-it_files/machine_learning_2x.png){width=40%}](https://xkcd.com/1838/)

The [Oxford Dictionary](https://www.google.com/search?q=define%3A+artificial+intelligence&oq=define%3A+artificial+intelligence&aqs=chrome..69i57j69i58.4225j0j7&sourceid=chrome&ie=UTF-8) defines AI as **(change this to a more reputable AI source)**

> the theory and development of computer systems able to perform tasks that normally require human intelligence, such as visual perception, speech recognition, decision-making, and translation between languages.

but this leaves me wanting more as well. Recent heralded advances in supposed AI like [AlphaGo](https://en.wikipedia.org/wiki/AlphaGo) and [OpenAI Five](https://openai.com/projects/five/) play games that humans normally play, beating the best humans in the world. But can these intelligent machines drive a car? or even navigate a maze?

***

Reading Francois Chollet's latest paper, *The Measure of Intelligence* gave me a much better understanding of how to evaluate AI. Chollet proposes an actionable definition for AI as well as a way to measure it. His goal is

> to point out the implicit assumptions our field has been working from, correct some of its most salient biases, and provide an actionable formal definition and measurement benchmark for human-like general intelligence, leveraging modern insight from developmental cognitive psychology.

The paper is organized into three sections: first, Chollet provides context and history around intelligence and AI, how both have been classically defined, and how this has impacted research into AI. Second, he proposes a new definition for AI. Finally, he provides a new dataset that can be used to benchmark AI against a formal definition of AI. I found all three sections to be extraordinarily useful in understanding AI and how to best think about it. What follows is my main takeaways from the paper.

###Context and history








